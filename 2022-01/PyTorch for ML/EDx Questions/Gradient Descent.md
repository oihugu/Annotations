# _0. PyTorch for ML::EDx Questions

## In gradient descent, what happens when you select a learning rate that is too large?

You may miss the minimum and your loss will start increasing


## How do you select an initial parameter value for the first iteration of gradient descent?

Randomly